{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 환경 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from krwordrank.word import KRWordRank\n",
    "from kiwipiepy import Kiwi\n",
    "from konlpy.tag import Kkma\n",
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc) :\n",
    "    doc = re.sub(r'[^\\w\\s]', \" \", doc)\n",
    "\n",
    "    # 인코딩 깨진 경우\n",
    "    doc = doc.replace(\"\\xa0\", \" \") # 공백문자\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/soyeon-stat/Bigdata/refs/heads/master/INSTIZ_CONTENTS.json'\n",
    "response = requests.get(url)\n",
    "jsonData = response.json()\n",
    "sentence = jsonData[0]['content'] # 예시데이터 : instiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 문장 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiwi = Kiwi()\n",
    "text_list = []\n",
    "for sent in kiwi.split_into_sents(sentence) :\n",
    "    _sent = clean_doc(sent.text)\n",
    "    text_list.append(_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 핵심어 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) 말뭉치 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = Kkma()\n",
    "corpus = [clean_doc(x) for x in text_list]\n",
    "\n",
    "# 명사로 토큰화\n",
    "tokenized_corpus = [\n",
    "    tagger.nouns(doc) for doc in corpus \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마플 부정적인 언급이 있어요전부터 억까라고 아무리 말해도 정정도 안되는거 같고 가수 욕먹는게 너무 답답해서 직접 자료 만들어와봤어 \n",
      "얼마전 초록글에서도 댓글에 반박할거있으면 제대로 설명가져와보라길래금발에 파란 염색 올라간거 그거 하나빼곤 다 반박해왔어\n",
      "그것도 찾으면 금발 파란 포인트 머리한 돌 여럿 나오긴 나와 \n",
      "같이 정리할까하다가 뺀 이유는 타돌 언급 최대한 안하고 싶어서도 있고나머지가 다 억까란걸 설명했으니 정말 겹치는게 생겼다해도 그건 우연일수도 있단걸 말하고 싶었어\n",
      "이거 읽고도 채원이가 윈터를 따라했다고 계속 믿고 억까하고 싶은 사람들 있을거고 안 말릴게 \n",
      "근데 소수라도 억까였구나 깨달아주는 사람이 있을것 같아서 정리했어\n",
      "내가 하고 싶은 말은 저 빨간글씨 날짜적힌 짤 자체가 억까라는 것과 머리 스타일이 좀 겹치더라도 그게 누가 누굴 따라했단게 되지는 않는다는거야 \n",
      "솔직히 아이돌들 스타일 다 비슷비슷 돌아가면서 하고 유행도 비슷하잖아 \n",
      "왜 억지로 엮어가면서 누굴 따라쟁이로 만들어야 속이 풀리는지 모르겠어 \n",
      "게다가 시작은 네이트판 정병인데아이돌들은 수많은 머리를 하고 거기서 서로 비슷한 느낌 찾는거 어려운일 아니야\n",
      "제발 이 정리글을 읽고 억까 좀 멈춰주면 좋겠어 \n",
      "자료는 억까있는 곳이면 퍼가도 되는데 가능하면 여기 지금 본문에 적은 이 설명도 같이 퍼가주면 좋겠어추천  34카카오톡 엑스\n"
     ]
    }
   ],
   "source": [
    "# 원본글\n",
    "for x in corpus : \n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) 핵심어 추출 : KRWordRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "누굴 : 2.7521570648948255\n",
      "같이 : 2.220973199809757\n",
      "자료 : 1.9432857034876556\n",
      "하고 : 1.8444746617250285\n",
      "머리 : 1.8332568786090562\n",
      "싶은 : 1.7698755412497542\n",
      "좋겠어 : 1.3373487417397945\n",
      "퍼가 : 1.134679729921292\n",
      "만들어 : 1.0873959177144814\n",
      "스타일 : 1.0628044301717359\n",
      "겹치 : 1.01481182411515\n",
      "사람 : 1.000373630966405\n",
      "파란 : 0.9883369821845991\n",
      "억까 : 0.9506499616606991\n",
      "비슷 : 0.8001183633898706\n",
      "읽고 : 0.792807107776494\n",
      "정리 : 0.7716618960026717\n",
      "설명 : 0.7636441609262122\n",
      "따라 : 0.6833157355968886\n",
      "반박 : 0.4555938786508919\n",
      "언급 : 0.4376544736921543\n"
     ]
    }
   ],
   "source": [
    "min_count = 2   # 단어의 최소 출현 빈도수 (그래프 생성 시)\n",
    "max_length = 10 # 단어의 최대 길이\n",
    "wordrank_extractor = KRWordRank(min_count=min_count, max_length=max_length)\n",
    "beta = 0.85    # PageRank의 decaying factor beta\n",
    "max_iter = 20\n",
    "keywords, rank, graph = wordrank_extractor.extract(corpus, beta, max_iter)\n",
    "\n",
    "for word, score in keywords.items() :\n",
    "    print(f'{word} : {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) 핵심어 추출 : TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = gensim.corpora.Dictionary(tokenized_corpus)\n",
    "tfidf = gensim.models.TfidfModel(dictionary=lexicon, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tfidf = pd.DataFrame()\n",
    "for doc in tokenized_corpus :\n",
    "    vec = lexicon.doc2bow(doc)\n",
    "    vec = tfidf[vec]\n",
    "    a = pd.DataFrame(vec, columns = ['label', 'score']) # 데이터프레임 생성\n",
    "    doc_tfidf = pd.concat([doc_tfidf, a])\n",
    "\n",
    "doc_tfidf = doc_tfidf.groupby('label')[['score']].mean().sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          score name\n",
      "label               \n",
      "60     0.590178   유행\n",
      "76     0.589439  정리글\n",
      "75     0.589439    이\n",
      "44     0.520502   윈터\n",
      "46     0.520502   채원\n",
      "...         ...  ...\n",
      "21     0.220069   설명\n",
      "10     0.213681   자료\n",
      "32     0.210549   머리\n",
      "1      0.123563    거\n",
      "6      0.090485    억\n",
      "\n",
      "[88 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "lexicon_dict = pd.DataFrame([x for x in lexicon.items()], columns = ['label', 'name'])\n",
    "lexicon_dict = lexicon_dict.set_index('label')\n",
    "print(doc_tfidf.join(lexicon_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) 핵심어 추출 : Key BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "from keybert import KeyBERT\n",
    "model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마플 부정적인 언급이 있어요전부터 억까라고 아무리 말해도 정정도 안되는거 같고 가수 욕먹는게 너무 답답해서 직접 자료 만들어와봤어 \n",
      "[('마플', 0.5912), ('요전', 0.5138), ('부정적', 0.5106), ('언급', 0.5077), ('직접', 0.4727)]\n",
      "얼마전 초록글에서도 댓글에 반박할거있으면 제대로 설명가져와보라길래금발에 파란 염색 올라간거 그거 하나빼곤 다 반박해왔어\n",
      "[('얼마', 0.606), ('초록', 0.5989), ('얼마전', 0.5739), ('초록글', 0.5638), ('보라', 0.5617)]\n",
      "그것도 찾으면 금발 파란 포인트 머리한 돌 여럿 나오긴 나와 \n",
      "[('포인트', 0.6579), ('머리', 0.5993), ('파란', 0.589), ('금발', 0.5194), ('여럿', 0.324)]\n",
      "같이 정리할까하다가 뺀 이유는 타돌 언급 최대한 안하고 싶어서도 있고나머지가 다 억까란걸 설명했으니 정말 겹치는게 생겼다해도 그건 우연일수도 있단걸 말하고 싶었어\n",
      "[('정리', 0.7271), ('이유', 0.603), ('일수', 0.5636), ('나머지', 0.5509), ('설명', 0.5452)]\n",
      "이거 읽고도 채원이가 윈터를 따라했다고 계속 믿고 억까하고 싶은 사람들 있을거고 안 말릴게 \n",
      "[('채원', 0.7088), ('사람', 0.634), ('이거', 0.6291), ('윈터', 0.2782)]\n",
      "근데 소수라도 억까였구나 깨달아주는 사람이 있을것 같아서 정리했어\n",
      "[('소수라', 0.7695), ('수라', 0.7031), ('사람', 0.6905), ('정리', 0.6486)]\n",
      "내가 하고 싶은 말은 저 빨간글씨 날짜적힌 짤 자체가 억까라는 것과 머리 스타일이 좀 겹치더라도 그게 누가 누굴 따라했단게 되지는 않는다는거야 \n",
      "[('글씨', 0.6176), ('스타일', 0.492), ('머리', 0.47), ('자체', 0.4642), ('내가', 0.4598)]\n",
      "솔직히 아이돌들 스타일 다 비슷비슷 돌아가면서 하고 유행도 비슷하잖아 \n",
      "[('아이돌', 0.7826), ('스타일', 0.7305), ('아이', 0.7173), ('유행', 0.6476)]\n",
      "왜 억지로 엮어가면서 누굴 따라쟁이로 만들어야 속이 풀리는지 모르겠어 \n",
      "[('억지', 0.7608), ('쟁이로', 0.7485), ('이로', 0.7006), ('누구', 0.4712)]\n",
      "게다가 시작은 네이트판 정병인데아이돌들은 수많은 머리를 하고 거기서 서로 비슷한 느낌 찾는거 어려운일 아니야\n",
      "[('아이돌', 0.5787), ('네이트판', 0.5687), ('아이', 0.5558), ('거기', 0.5362), ('시작', 0.5324)]\n",
      "제발 이 정리글을 읽고 억까 좀 멈춰주면 좋겠어 \n",
      "[('정리', 0.821), ('정리글', 0.8065)]\n",
      "자료는 억까있는 곳이면 퍼가도 되는데 가능하면 여기 지금 본문에 적은 이 설명도 같이 퍼가주면 좋겠어추천  34카카오톡 엑스\n",
      "[('카카오', 0.6656), ('34카카오', 0.6507), ('자료', 0.6263), ('여기', 0.5659), ('추천', 0.5306)]\n"
     ]
    }
   ],
   "source": [
    "# 문장별 키워드\n",
    "nouns = [\",\".join(x) for x in tokenized_corpus]\n",
    "for sentence, keyword in zip(corpus, model.extract_keywords(nouns)) :\n",
    "    print(sentence)\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마플 부정적인 언급이 있어요전부터 억까라고 아무리 말해도 정정도 안되는거 같고 가수 욕먹는게 너무 답답해서 직접 자료 만들어와봤어 \n",
      "얼마전 초록글에서도 댓글에 반박할거있으면 제대로 설명가져와보라길래금발에 파란 염색 올라간거 그거 하나빼곤 다 반박해왔어\n",
      "그것도 찾으면 금발 파란 포인트 머리한 돌 여럿 나오긴 나와 \n",
      "같이 정리할까하다가 뺀 이유는 타돌 언급 최대한 안하고 싶어서도 있고나머지가 다 억까란걸 설명했으니 정말 겹치는게 생겼다해도 그건 우연일수도 있단걸 말하고 싶었어\n",
      "이거 읽고도 채원이가 윈터를 따라했다고 계속 믿고 억까하고 싶은 사람들 있을거고 안 말릴게 \n",
      "근데 소수라도 억까였구나 깨달아주는 사람이 있을것 같아서 정리했어\n",
      "내가 하고 싶은 말은 저 빨간글씨 날짜적힌 짤 자체가 억까라는 것과 머리 스타일이 좀 겹치더라도 그게 누가 누굴 따라했단게 되지는 않는다는거야 \n",
      "솔직히 아이돌들 스타일 다 비슷비슷 돌아가면서 하고 유행도 비슷하잖아 \n",
      "왜 억지로 엮어가면서 누굴 따라쟁이로 만들어야 속이 풀리는지 모르겠어 \n",
      "게다가 시작은 네이트판 정병인데아이돌들은 수많은 머리를 하고 거기서 서로 비슷한 느낌 찾는거 어려운일 아니야\n",
      "제발 이 정리글을 읽고 억까 좀 멈춰주면 좋겠어 \n",
      "자료는 억까있는 곳이면 퍼가도 되는데 가능하면 여기 지금 본문에 적은 이 설명도 같이 퍼가주면 좋겠어추천  34카카오톡 엑스\n",
      "[('정병', 0.4822), ('설명', 0.4358), ('정정', 0.4277), ('부정적', 0.4237), ('억지', 0.4173)]\n"
     ]
    }
   ],
   "source": [
    "# 전체 문서를 기준으로\n",
    "nouns = [\",\".join(x) for x in tokenized_corpus]\n",
    "nouns = \",\".join(nouns)\n",
    "for x in corpus :\n",
    "    print(x)\n",
    "print(model.extract_keywords(nouns))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
