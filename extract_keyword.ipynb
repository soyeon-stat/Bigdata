{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 환경 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from krwordrank.word import KRWordRank\n",
    "from kiwipiepy import Kiwi\n",
    "from konlpy.tag import Hannanum\n",
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc) :\n",
    "    doc = re.sub(r'[^\\w\\s]', \" \", doc)\n",
    "\n",
    "    # 인코딩 깨진 경우\n",
    "    doc = doc.replace(\"\\xa0\", \" \") # 공백문자\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/soyeon-stat/Bigdata/refs/heads/master/INSTIZ_CONTENTS.json'\n",
    "response = requests.get(url)\n",
    "jsonData = response.json()\n",
    "sentence = jsonData[0]['content'] # 예시데이터 : instiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 문장 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiwi = Kiwi()\n",
    "text_list = []\n",
    "for sent in kiwi.split_into_sents(sentence) :\n",
    "    _sent = clean_doc(sent.text)\n",
    "    text_list.append(_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 핵심어 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) 말뭉치 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "han = Hannanum()\n",
    "corpus = [clean_doc(x) for x in text_list]\n",
    "\n",
    "# 명사로 토큰화\n",
    "tokenized_corpus = [\n",
    "    han.nouns(doc) for doc in corpus \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마플 부정적인 언급이 있어요전부터 억까라고 아무리 말해도 정정도 안되는거 같고 가수 욕먹는게 너무 답답해서 직접 자료 만들어와봤어 \n",
      "얼마전 초록글에서도 댓글에 반박할거있으면 제대로 설명가져와보라길래금발에 파란 염색 올라간거 그거 하나빼곤 다 반박해왔어\n",
      "그것도 찾으면 금발 파란 포인트 머리한 돌 여럿 나오긴 나와 \n",
      "같이 정리할까하다가 뺀 이유는 타돌 언급 최대한 안하고 싶어서도 있고나머지가 다 억까란걸 설명했으니 정말 겹치는게 생겼다해도 그건 우연일수도 있단걸 말하고 싶었어\n",
      "이거 읽고도 채원이가 윈터를 따라했다고 계속 믿고 억까하고 싶은 사람들 있을거고 안 말릴게 \n",
      "근데 소수라도 억까였구나 깨달아주는 사람이 있을것 같아서 정리했어\n",
      "내가 하고 싶은 말은 저 빨간글씨 날짜적힌 짤 자체가 억까라는 것과 머리 스타일이 좀 겹치더라도 그게 누가 누굴 따라했단게 되지는 않는다는거야 \n",
      "솔직히 아이돌들 스타일 다 비슷비슷 돌아가면서 하고 유행도 비슷하잖아 \n",
      "왜 억지로 엮어가면서 누굴 따라쟁이로 만들어야 속이 풀리는지 모르겠어 \n",
      "게다가 시작은 네이트판 정병인데아이돌들은 수많은 머리를 하고 거기서 서로 비슷한 느낌 찾는거 어려운일 아니야\n",
      "제발 이 정리글을 읽고 억까 좀 멈춰주면 좋겠어 \n",
      "자료는 억까있는 곳이면 퍼가도 되는데 가능하면 여기 지금 본문에 적은 이 설명도 같이 퍼가주면 좋겠어추천  34카카오톡 엑스\n"
     ]
    }
   ],
   "source": [
    "# 원본글\n",
    "for x in corpus : \n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) 핵심어 추출 : KRWordRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "누굴 : 2.7521570648948255\n",
      "같이 : 2.220973199809757\n",
      "자료 : 1.9432857034876556\n",
      "하고 : 1.8444746617250285\n",
      "머리 : 1.8332568786090562\n",
      "싶은 : 1.7698755412497542\n",
      "좋겠어 : 1.3373487417397945\n",
      "퍼가 : 1.134679729921292\n",
      "만들어 : 1.0873959177144814\n",
      "스타일 : 1.0628044301717359\n",
      "겹치 : 1.01481182411515\n",
      "사람 : 1.000373630966405\n",
      "파란 : 0.9883369821845991\n",
      "억까 : 0.9506499616606991\n",
      "비슷 : 0.8001183633898706\n",
      "읽고 : 0.792807107776494\n",
      "정리 : 0.7716618960026717\n",
      "설명 : 0.7636441609262122\n",
      "따라 : 0.6833157355968886\n",
      "반박 : 0.4555938786508919\n",
      "언급 : 0.4376544736921543\n"
     ]
    }
   ],
   "source": [
    "min_count = 2   # 단어의 최소 출현 빈도수 (그래프 생성 시)\n",
    "max_length = 10 # 단어의 최대 길이\n",
    "wordrank_extractor = KRWordRank(min_count=min_count, max_length=max_length)\n",
    "beta = 0.85    # PageRank의 decaying factor beta\n",
    "max_iter = 20\n",
    "keywords, rank, graph = wordrank_extractor.extract(corpus, beta, max_iter)\n",
    "\n",
    "for word, score in keywords.items() :\n",
    "    print(f'{word} : {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) 핵심어 추출 : TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = gensim.corpora.Dictionary(tokenized_corpus)\n",
    "tfidf = gensim.models.TfidfModel(dictionary=lexicon, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tfidf = pd.DataFrame()\n",
    "for doc in tokenized_corpus :\n",
    "    vec = lexicon.doc2bow(doc)\n",
    "    vec = tfidf[vec]\n",
    "    a = pd.DataFrame(vec, columns = ['label', 'score']) # 데이터프레임 생성\n",
    "    doc_tfidf = pd.concat([doc_tfidf, a])\n",
    "\n",
    "doc_tfidf = doc_tfidf.groupby('label')[['score']].mean().sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          score  name\n",
      "label                \n",
      "78     0.811128   정리글\n",
      "71     0.629950     속\n",
      "70     0.629950  따라쟁이\n",
      "69     0.470364    유행\n",
      "66     0.470364  비슷비슷\n",
      "...         ...   ...\n",
      "9      0.240958    자료\n",
      "59     0.240520    머리\n",
      "7      0.225686    언급\n",
      "30     0.224551    설명\n",
      "3      0.170383     말\n",
      "\n",
      "[87 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "lexicon_dict = pd.DataFrame([x for x in lexicon.items()], columns = ['label', 'name'])\n",
    "lexicon_dict = lexicon_dict.set_index('label')\n",
    "print(doc_tfidf.join(lexicon_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
